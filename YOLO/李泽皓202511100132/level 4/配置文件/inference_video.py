# inference_video.py
import cv2
from ultralytics import YOLO
import os

def detect_video(model, video_path, output_dir="outputs", conf_threshold=0.25):
    """
    å¯¹è§†é¢‘æ–‡ä»¶è¿›è¡Œè½¦ç‰Œæ£€æµ‹
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"ğŸ¥ è§†é¢‘ä¿¡æ¯: {fps}FPS, åˆ†è¾¨ç‡: {width}x{height}, æ€»å¸§æ•°: {total_frames}")
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    output_path = os.path.join(output_dir, "detected_video.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    detection_count = 0
    
    print("â³ å¼€å§‹å¤„ç†è§†é¢‘...")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # è¿›è¡Œæ¨ç†
        results = model.predict(
            source=frame,
            conf=conf_threshold,
            verbose=False  # ä¸æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        )
        
        # å¤„ç†å½“å‰å¸§çš„ç»“æœ
        result = results[0]
        annotated_frame = result.plot()
        
        # ç»Ÿè®¡æ£€æµ‹ç»“æœ
        if len(result.boxes) > 0:
            detection_count += 1
        
        # å†™å…¥è¾“å‡ºè§†é¢‘
        out.write(annotated_frame)
        
        # æ˜¾ç¤ºå®æ—¶é¢„è§ˆï¼ˆå¯é€‰ï¼‰
        cv2.imshow('Video Detection', annotated_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):  # æŒ‰Qé”®é€€å‡º
            break
        
        frame_count += 1
        if frame_count % 30 == 0:  # æ¯30å¸§æ‰“å°ä¸€æ¬¡è¿›åº¦
            progress = (frame_count / total_frames) * 100
            print(f"ğŸ“Š å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_count}/{total_frames})")
    
    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    
    print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»å¸§æ•°: {frame_count}")
    print(f"   - æ£€æµ‹åˆ°è½¦ç‰Œçš„å¸§æ•°: {detection_count}")
    print(f"   - æ£€æµ‹ç‡: {(detection_count/frame_count)*100:.1f}%")
    print(f"   - è¾“å‡ºæ–‡ä»¶: {output_path}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åŠ è½½æ¨¡å‹
    model_path = "runs/detect/license_plate_detection_v1/weights/best.pt"
    model = load_model(model_path)
    
    # æ£€æµ‹è§†é¢‘æ–‡ä»¶
    video_path = "test_videos/traffic.mp4"  # è¯·æ›¿æ¢ä¸ºä½ çš„è§†é¢‘è·¯å¾„
    detect_video(model, video_path)